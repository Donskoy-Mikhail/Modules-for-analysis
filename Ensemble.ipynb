{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool, cv\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "# from category_encoders import TargetEncoder\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime as dat\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78e9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa21e7-7113-4df8-a90c-24b65b7db5f9",
   "metadata": {},
   "source": [
    "class StackingAveragedModels():\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a257d84-542c-4a6c-a22c-9d0a9914f9e5",
   "metadata": {},
   "source": [
    "# Рандомный поиск для XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e4d7f-995e-447a-8ce0-55e6be608685",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_col = 'TARGET'\n",
    "features_cols = train.drop([\"id_contract\",\"TARGET\", \"id_client\"] , axis='columns').select_dtypes(include=[np.number]).columns.tolist() \n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=1500, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "params = {\n",
    "        \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, scoring='roc_auc', n_jobs=4, cv=3, verbose=3, random_state=1001 )\n",
    "\n",
    "\n",
    "random_search.fit(train[features_cols], train[lable_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262c081-36ad-4886-980e-c4c1867acd8b",
   "metadata": {},
   "source": [
    "# Баейсовский поиск для XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e6cc9-7ef7-43e5-9ecf-a365627852d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_col = 'TARGET'\n",
    "features_cols = train.drop([\"id_contract\",\"TARGET\", \"id_client\"] , axis='columns').select_dtypes(include=[np.number]).columns.tolist() \n",
    "model = XGBClassifier(learning_rate=0.02, n_estimators=1500, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "search_space = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "}\n",
    "def objective(params, model,  X_train, y_train):\n",
    "    \"\"\"\n",
    "    Кросс-валидация с текущими гиперпараметрами\n",
    "\n",
    "    :params: гиперпараметры\n",
    "    :model: модель\n",
    "    :X_train: матрица признаков\n",
    "    :y_train: вектор меток объектов\n",
    "    :return: средняя точность на кросс-валидации\n",
    "    \"\"\" \n",
    "    \n",
    "    # задаём модели требуемые параметры    \n",
    "    model.set_params(**params)\n",
    "   \n",
    "    # задаём параметры кросс-валидации (стратифицированная 4-фолдовая с перемешиванием)\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "    # проводим кросс-валидацию  \n",
    "    score = cross_val_score(estimator=model, X=X_train, y=y_train, \n",
    "                            scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    print(score.mean(), print(params))\n",
    "    # возвращаем результаты, которые записываются в Trials()\n",
    "    return   {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin( \n",
    "          # функция для оптимизации  \n",
    "            fn=partial(objective, model=model, X_train=train[features_cols], y_train= train[lable_col]),\n",
    "          # пространство поиска гиперпараметров  \n",
    "            space=search_space,\n",
    "          # алгоритм поиска\n",
    "            algo=tpe.suggest,\n",
    "          # число итераций \n",
    "          # (можно ещё указать и время поиска) \n",
    "            max_evals=100,\n",
    "          # куда сохранять историю поиска\n",
    "            trials=trials,\n",
    "          # random state\n",
    "            rstate=np.random.RandomState(1),\n",
    "          # progressbar\n",
    "            show_progressbar=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593db99-7959-42dd-9a57-43d9a9478957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_results(hp_results):\n",
    "    \"\"\"\n",
    "    Отображаем результаты hyperopt в формате DataFrame \n",
    "\n",
    "    :hp_results: результаты hyperop\n",
    "    :return: pandas DataFrame\n",
    "    \"\"\" \n",
    "\n",
    "    results = pd.DataFrame([{**x, **x['params']} for x in  hp_results])\n",
    "    results.drop(labels=['status', 'params'], axis=1, inplace=True)\n",
    "    results.sort_values(by=['loss'], ascending=False, inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fc855-2985-4d9c-beca-903e5e6eed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results(trials.results))\n",
    "df_results(trials.results).to_csv('params.csv', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe260a0d-f8e8-43f1-8e8c-5292b042396d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719eb3da-55ec-4704-b346-b2b45258bb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab26d44-d3d4-46e4-9fbf-490cc65649a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1de56-f7b1-4f4c-9d59-650b0e0d7965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01916a06-33dc-4ed3-b9f8-f158621e7e43",
   "metadata": {},
   "source": [
    "# Поиск по сетке catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa43c0d-6a31-446c-a0ea-02bd37bb730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_col = 'TARGET'\n",
    "features_cols = train.drop([\"id_contract\",\"TARGET\", \"id_client\"], axis='columns').select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "model = CatBoostClassifier(silent = True, eval_metric = 'AUC')\n",
    "\n",
    "grid = {'learning_rate': [0.03, 0.1],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "grid_search_result = model.grid_search(grid,\n",
    "                                       X=train[features_cols],\n",
    "                                       y=train[lable_col],\n",
    "                                       plot=True,\n",
    "                                       refit = True,cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a207f-493b-418d-8330-cfb270fedff8",
   "metadata": {},
   "source": [
    "# Байесовский поиск Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e40dc-068a-4d94-84d3-dcc4fb79d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"OKVED_CODE\",\"OKTMO_CODE\"]\n",
    "\n",
    "modelc = CatBoostClassifier(silent = True, eval_metric = 'AUC', cat_features = cat_cols, early_stopping_rounds = 50)\n",
    "\n",
    "def objective(params, model,  X_train, y_train):\n",
    "    \"\"\"\n",
    "    Кросс-валидация с текущими гиперпараметрами\n",
    "\n",
    "    :params: гиперпараметры\n",
    "    :model: модель\n",
    "    :X_train: матрица признаков\n",
    "    :y_train: вектор меток объектов\n",
    "    :return: средняя точность на кросс-валидации\n",
    "    \"\"\" \n",
    "    \n",
    "    # задаём модели требуемые параметры    \n",
    "    model.set_params(**params)\n",
    "   \n",
    "    # задаём параметры кросс-валидации (стратифицированная 4-фолдовая с перемешиванием)\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "    # проводим кросс-валидацию  \n",
    "    score = cross_val_score(estimator=model, X=X_train, y=y_train, \n",
    "                            scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    print(score.mean(), print(params))\n",
    "    # возвращаем результаты, которые записываются в Trials()\n",
    "    return   {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin( \n",
    "          # функция для оптимизации  \n",
    "            fn=partial(objective, model=modelc, X_train=train[features_cols], y_train= train[lable_col]),\n",
    "          # пространство поиска гиперпараметров  \n",
    "            space=search_space,\n",
    "          # алгоритм поиска\n",
    "            algo=tpe.suggest,\n",
    "          # число итераций \n",
    "          # (можно ещё указать и время поиска) \n",
    "            max_evals=100,\n",
    "          # куда сохранять историю поиска\n",
    "            trials=trials,\n",
    "          # random state\n",
    "            rstate=np.random.RandomState(1),\n",
    "          # progressbar\n",
    "            show_progressbar=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecf9da-468a-4e6b-849c-f8ec6a7ce341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a7a12-d7fb-4b2c-b510-77f124807273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f33666-145f-45be-a3b1-92afb0e6ee38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613fcc5-5904-4549-83df-e944cc01c8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e706c456-d3d9-44f8-bfaa-ba3c87e8eb13",
   "metadata": {},
   "source": [
    "## Байесовский поиск LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60be6a-863e-4b71-9637-9ce3736c850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_col = 'TARGET'\n",
    "features_cols = train.drop([\"id_contract\",\"TARGET\", \"id_client\"] , axis='columns').select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "model = lgb.LGBMClassifier(boosting_type= 'dart', \n",
    "          objective = 'binary', \n",
    "          silent = True,\n",
    "          num_iterations = 1500,\n",
    "          max_depth = -1\n",
    "                        )\n",
    "\n",
    "search_space = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     hp.choice(label='n_estimators', options = np.linspace(0,2000,30,dtype = \"int\"))\n",
    "}\n",
    "\n",
    "def objective(params, model,  X_train, y_train):\n",
    "    \"\"\"\n",
    "    Кросс-валидация с текущими гиперпараметрами\n",
    "\n",
    "    :params: гиперпараметры\n",
    "    :model: модель\n",
    "    :X_train: матрица признаков\n",
    "    :y_train: вектор меток объектов\n",
    "    :return: средняя точность на кросс-валидации\n",
    "    \"\"\" \n",
    "    \n",
    "    # задаём модели требуемые параметры    \n",
    "    model.set_params(**params)\n",
    "   \n",
    "    # задаём параметры кросс-валидации (стратифицированная 4-фолдовая с перемешиванием)\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "    # проводим кросс-валидацию  \n",
    "    score = cross_val_score(estimator=model, X=X_train, y=y_train, \n",
    "                            scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    print(score.mean(), print(params))\n",
    "    # возвращаем результаты, которые записываются в Trials()\n",
    "    return   {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin( \n",
    "          # функция для оптимизации  \n",
    "            fn=partial(objective, model=model, X_train=train[features_cols], y_train= train[lable_col]),\n",
    "          # пространство поиска гиперпараметров  \n",
    "            space=search_space,\n",
    "          # алгоритм поиска\n",
    "            algo=tpe.suggest,\n",
    "          # число итераций \n",
    "          # (можно ещё указать и время поиска) \n",
    "            max_evals=100,\n",
    "          # куда сохранять историю поиска\n",
    "            trials=trials,\n",
    "          # random state\n",
    "            rstate=np.random.RandomState(1),\n",
    "          # progressbar\n",
    "            show_progressbar=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201cddfb-9716-4dca-a351-5f9af48fe46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_results(hp_results):\n",
    "    \"\"\"\n",
    "    Отображаем результаты hyperopt в формате DataFrame \n",
    "\n",
    "    :hp_results: результаты hyperop\n",
    "    :return: pandas DataFrame\n",
    "    \"\"\" \n",
    "\n",
    "    results = pd.DataFrame([{**x, **x['params']} for x in  hp_results])\n",
    "    results.drop(labels=['status', 'params'], axis=1, inplace=True)\n",
    "    results.sort_values(by=['loss'], ascending=False, inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389d95e-22e4-422b-a394-12e4fc3ad0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results(trials.results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa742cb-086b-44aa-bed1-b709db46c689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
