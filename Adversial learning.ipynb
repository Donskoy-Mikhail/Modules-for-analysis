{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f91dae-b73d-41de-9bd9-f6d599daec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool, cv\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "# from category_encoders import TargetEncoder\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime as dat\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea9bd6-9276-46b7-b0e0-73ba42ef7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dataset_label'] = 0\n",
    "test['dataset_label'] = 1\n",
    "target = 'dataset_label'\n",
    "\n",
    "def create_adversarial_data(df_train, df_test, cols, N_val=7000):\n",
    "    df_master = pd.concat([df_train[cols], df_test[cols]], axis=0)\n",
    "    adversarial_val = df_master.sample(N_val, replace=False)\n",
    "    adversarial_train = df_master[\n",
    "        ~df_master.index.isin(adversarial_val.index)\n",
    "    ]\n",
    "    return adversarial_train, adversarial_val\n",
    "\n",
    "all_cols = train.drop([\"id_contract\",\"TARGET\", \"id_client\"] , axis='columns').select_dtypes(include=[np.number]).columns.tolist() + []\n",
    "\n",
    "cat_cols = []\n",
    "features_cols = train.drop([\"id_contract\",\"TARGET\", \"id_client\", 'dataset_label'] , axis='columns').select_dtypes(include=[np.number]).columns.tolist() + []\n",
    "\n",
    "adversarial_train, adversarial_test = create_adversarial_data(train, test, all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a9d97-ab11-4914-ac4c-5ad43ff20667",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Pool(\n",
    "    data=adversarial_train[features_cols],\n",
    "    label=adversarial_train[target],\n",
    "    cat_features=cat_cols\n",
    ")\n",
    "holdout_data = Pool(\n",
    "    data=adversarial_test[features_cols],\n",
    "    label=adversarial_test[target],\n",
    "    cat_features=cat_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548dbc5-317b-4461-a8c2-c8612fc6bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 100,\n",
    "    'eval_metric': 'AUC',\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 50,\n",
    "    \"depth\": 2\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "_ = model.fit(train_data, eval_set=holdout_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c8b64-fc7b-41fc-b0b7-a8dbb28f90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance =pd.DataFrame({'feature_importance': model.get_feature_importance(), \n",
    "              'feature_names': adversarial_train[features_cols].columns}).sort_values(by=['feature_importance'], \n",
    "                                                           ascending=False)\n",
    "feature_importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
